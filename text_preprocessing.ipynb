{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqTgHcj6vT4YiBTQXpekvV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chahat7414gupta/10-days-of-NLP/blob/main/text_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYS8omZ0fXq0",
        "outputId": "fc1daec1-b4d1-43b8-9c22-4d02c8658ccd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "para=\"\"\"\n",
        "Machine learning is a branch of artificial intelligence (AI) and computer science which focuses on the use of data and algorithms to imitate the way that humans learn, gradually improving its accuracy.\n",
        "\n",
        "IBM has a rich history with machine learning. One of its own, Arthur Samuel, is credited for coining the term, “machine learning” with his research (PDF, 481 KB) (link resides outside IBM) around the game of checkers. Robert Nealey, the self-proclaimed checkers master, played the game on an IBM 7094 computer in 1962, and he lost to the computer. Compared to what can be done today, this feat seems trivial, but it’s considered a major milestone in the field of artificial intelligence.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "_eklnZ9mflJC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "para"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "XzsIWE0Df0bg",
        "outputId": "41ed3959-63be-4399-9d44-c329cae82dea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nMachine learning is a branch of artificial intelligence (AI) and computer science which focuses on the use of data and algorithms to imitate the way that humans learn, gradually improving its accuracy.\\n\\nIBM has a rich history with machine learning. One of its own, Arthur Samuel, is credited for coining the term, “machine learning” with his research (PDF, 481 KB) (link resides outside IBM) around the game of checkers. Robert Nealey, the self-proclaimed checkers master, played the game on an IBM 7094 computer in 1962, and he lost to the computer. Compared to what can be done today, this feat seems trivial, but it’s considered a major milestone in the field of artificial intelligence.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "C1YXIiHQf1ZI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iebeCLWFgmkk",
        "outputId": "29967323-ca48-4859-aa0d-bf3fa912907d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence=nltk.sent_tokenize(para)"
      ],
      "metadata": {
        "id": "nJyL0Wi3hmqn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer=PorterStemmer()"
      ],
      "metadata": {
        "id": "hZaya1W_htYm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer.stem('going')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "FHh_-lfjh_T5",
        "outputId": "6f5273c7-5d2f-4fff-f3e9-73aef003f7af"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'go'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer.stem('chahat')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "6XsNFHL8iHXV",
        "outputId": "8cfd3bf3-ca9b-4928-f74a-2f5c9ca3bfa6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'chahat'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer.stem('psychology')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "BqACJDcxiK4W",
        "outputId": "08619550-2ea8-4af0-ef7f-d9bbc3fd6e1d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'psycholog'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "cOTX-Nm5iO5L"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmetization=WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "FxUuvnGWiq_e"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffxuv-avi8Du",
        "outputId": "7785d157-6ddd-44a4-9108-536a1ab3cef9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmetization.lemmatize('going')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lvt5nPPiiwrP",
        "outputId": "b304064b-8b4e-4c83-f408-388d3b1a5952"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'going'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmetization.lemmatize('psychology')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "uzeoCTD1i0_2",
        "outputId": "54dc84c9-d876-4097-be9a-225579b0671d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'psychology'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "vDLPR9P4jCpq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus=[]\n",
        "for i in range(len(sentence)):\n",
        "    review=re.sub('[^a-zA-z]',' ',sentence[i])\n",
        "    review=review.lower()\n",
        "    corpus.append(review)"
      ],
      "metadata": {
        "id": "7eXltp8VzIA1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9fHJfXDzjjy",
        "outputId": "41837b9d-076c-45b1-f324-79a40b33ac3d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' machine learning is a branch of artificial intelligence  ai  and computer science which focuses on the use of data and algorithms to imitate the way that humans learn  gradually improving its accuracy ',\n",
              " 'ibm has a rich history with machine learning ',\n",
              " 'one of its own  arthur samuel  is credited for coining the term   machine learning  with his research  pdf      kb   link resides outside ibm  around the game of checkers ',\n",
              " 'robert nealey  the self proclaimed checkers master  played the game on an ibm      computer in       and he lost to the computer ',\n",
              " 'compared to what can be done today  this feat seems trivial  but it s considered a major milestone in the field of artificial intelligence ']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EbvEIFt9hAK",
        "outputId": "93e6d402-a005-4486-ab51-3132bcd4c20d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "# Extract words fro paragraph\n",
        "#stemming\n",
        "for i in corpus:\n",
        "    word=nltk.word_tokenize(i)\n",
        "    ###### This is for tokenization ########### then we have to extract the stopwords form the data\n",
        "    for words in word:\n",
        "        if words  not in set(stopwords.words('english')):\n",
        "            ### Extracting the stopwords\n",
        "            print(stemmer.stem(words)) ## then we have to stem the data \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyp6TlIR0YiE",
        "outputId": "5698cc58-c882-4959-953e-8409365602c6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "machin\n",
            "learn\n",
            "branch\n",
            "artifici\n",
            "intellig\n",
            "ai\n",
            "comput\n",
            "scienc\n",
            "focus\n",
            "use\n",
            "data\n",
            "algorithm\n",
            "imit\n",
            "way\n",
            "human\n",
            "learn\n",
            "gradual\n",
            "improv\n",
            "accuraci\n",
            "ibm\n",
            "rich\n",
            "histori\n",
            "machin\n",
            "learn\n",
            "one\n",
            "arthur\n",
            "samuel\n",
            "credit\n",
            "coin\n",
            "term\n",
            "machin\n",
            "learn\n",
            "research\n",
            "pdf\n",
            "kb\n",
            "link\n",
            "resid\n",
            "outsid\n",
            "ibm\n",
            "around\n",
            "game\n",
            "checker\n",
            "robert\n",
            "nealey\n",
            "self\n",
            "proclaim\n",
            "checker\n",
            "master\n",
            "play\n",
            "game\n",
            "ibm\n",
            "comput\n",
            "lost\n",
            "comput\n",
            "compar\n",
            "done\n",
            "today\n",
            "feat\n",
            "seem\n",
            "trivial\n",
            "consid\n",
            "major\n",
            "mileston\n",
            "field\n",
            "artifici\n",
            "intellig\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.words('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3zWUrbI3f6v",
        "outputId": "e43512b1-fab0-413f-9295-5c82db3c7f14"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aohx9uBL3Zb-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Preprocessing\n",
        "\n",
        "--- Above code shows in the output that words has no meaning\n",
        "\n",
        "\n",
        "--- then we have to apply lemmentizer\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zKdHHNSy6SFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "# Extract words fro paragraph\n",
        "#stemming\n",
        "for i in corpus:\n",
        "    word=nltk.word_tokenize(i)\n",
        "    ###### This is for tokenization ########### then we have to extract the stopwords form the data\n",
        "    for words in word:\n",
        "        if words  not in set(stopwords.words('english')):\n",
        "            ### Extracting the stopwords\n",
        "            print(lemmetization.lemmatize(words)) ## then we have to lemmentize  the data "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LW9puPB26m_j",
        "outputId": "2b31f435-0d4c-4a38-f5de-041dc0f50232"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "machine\n",
            "learning\n",
            "branch\n",
            "artificial\n",
            "intelligence\n",
            "ai\n",
            "computer\n",
            "science\n",
            "focus\n",
            "use\n",
            "data\n",
            "algorithm\n",
            "imitate\n",
            "way\n",
            "human\n",
            "learn\n",
            "gradually\n",
            "improving\n",
            "accuracy\n",
            "ibm\n",
            "rich\n",
            "history\n",
            "machine\n",
            "learning\n",
            "one\n",
            "arthur\n",
            "samuel\n",
            "credited\n",
            "coining\n",
            "term\n",
            "machine\n",
            "learning\n",
            "research\n",
            "pdf\n",
            "kb\n",
            "link\n",
            "resides\n",
            "outside\n",
            "ibm\n",
            "around\n",
            "game\n",
            "checker\n",
            "robert\n",
            "nealey\n",
            "self\n",
            "proclaimed\n",
            "checker\n",
            "master\n",
            "played\n",
            "game\n",
            "ibm\n",
            "computer\n",
            "lost\n",
            "computer\n",
            "compared\n",
            "done\n",
            "today\n",
            "feat\n",
            "seems\n",
            "trivial\n",
            "considered\n",
            "major\n",
            "milestone\n",
            "field\n",
            "artificial\n",
            "intelligence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "6kn4Lw7jBTfS",
        "outputId": "220f5de7-ba8b-4352-c65e-31c8d5c61a4a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' machine learning is a branch of artificial intelligence  ai  and computer science which focuses on the use of data and algorithms to imitate the way that humans learn  gradually improving its accuracy '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus=[]\n",
        "for i in range(len(sentence)):\n",
        "    review=re.sub('[^a-zA-Z]',' ',sentence[i])\n",
        "    review=review.lower()\n",
        "    review=review.split()\n",
        "    review=[lemmetization.lemmatize(words)  for words in review if words  not in set(stopwords.words('english'))]\n",
        "    review=\" \".join(review)\n",
        "    corpus.append(review)\n"
      ],
      "metadata": {
        "id": "P49Ege_nBos4"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0hX8xFxDTce",
        "outputId": "cb9961e9-6fa8-46b5-a0b8-f53567a7d236"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['machine learning branch artificial intelligence ai computer science focus use data algorithm imitate way human learn gradually improving accuracy',\n",
              " 'ibm rich history machine learning',\n",
              " 'one arthur samuel credited coining term machine learning research pdf kb link resides outside ibm around game checker',\n",
              " 'robert nealey self proclaimed checker master played game ibm computer lost computer',\n",
              " 'compared done today feat seems trivial considered major milestone field artificial intelligence']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "iZIVMYwH6-0J"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv=CountVectorizer(binary=True)"
      ],
      "metadata": {
        "id": "jnvEqzxLBEJ9"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=cv.fit_transform(corpus)"
      ],
      "metadata": {
        "id": "Q2P7EFKGBJVI"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aE2VI6eBP7J",
        "outputId": "6e7f0eca-6250-47d6-d954-c640a0c96bfd"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'machine': 31,\n",
              " 'learning': 28,\n",
              " 'branch': 6,\n",
              " 'artificial': 5,\n",
              " 'intelligence': 25,\n",
              " 'ai': 1,\n",
              " 'computer': 10,\n",
              " 'science': 46,\n",
              " 'focus': 17,\n",
              " 'use': 52,\n",
              " 'data': 13,\n",
              " 'algorithm': 2,\n",
              " 'imitate': 23,\n",
              " 'way': 53,\n",
              " 'human': 21,\n",
              " 'learn': 27,\n",
              " 'gradually': 19,\n",
              " 'improving': 24,\n",
              " 'accuracy': 0,\n",
              " 'ibm': 22,\n",
              " 'rich': 43,\n",
              " 'history': 20,\n",
              " 'one': 36,\n",
              " 'arthur': 4,\n",
              " 'samuel': 45,\n",
              " 'credited': 12,\n",
              " 'coining': 8,\n",
              " 'term': 49,\n",
              " 'research': 41,\n",
              " 'pdf': 38,\n",
              " 'kb': 26,\n",
              " 'link': 29,\n",
              " 'resides': 42,\n",
              " 'outside': 37,\n",
              " 'around': 3,\n",
              " 'game': 18,\n",
              " 'checker': 7,\n",
              " 'robert': 44,\n",
              " 'nealey': 35,\n",
              " 'self': 48,\n",
              " 'proclaimed': 40,\n",
              " 'master': 33,\n",
              " 'played': 39,\n",
              " 'lost': 30,\n",
              " 'compared': 9,\n",
              " 'done': 14,\n",
              " 'today': 50,\n",
              " 'feat': 15,\n",
              " 'seems': 47,\n",
              " 'trivial': 51,\n",
              " 'considered': 11,\n",
              " 'major': 32,\n",
              " 'milestone': 34,\n",
              " 'field': 16}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0].toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6ByAyrhBj25",
        "outputId": "e6370ebc-d587-4ab8-fd29-7aa54c1fb4a9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
              "        0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 0, 0, 0, 0, 0, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Heo8vSInEG2i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}